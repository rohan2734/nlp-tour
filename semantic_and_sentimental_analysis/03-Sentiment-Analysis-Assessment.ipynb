{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Assessment - Solution\n",
    "\n",
    "## Task #1: Perform vector arithmetic on your own words\n",
    "Write code that evaluates vector arithmetic on your own set of related words. The goal is to come as close to an expected word as possible. Please feel free to share success stories in the Q&A Forum for this section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy and load the language library. Remember to use a larger model!\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_lg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the words you wish to compare, and obtain their vectors\n",
    "# nlp(u\"rohan is a smart boy\").vector\n",
    "word1=nlp.vocab['wolf'].vector\n",
    "word2=nlp.vocab['dog'].vector\n",
    "word3=nlp.vocab['cat'].vector\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spatial and define a cosine_similarity function\n",
    "from scipy import spatial\n",
    "\n",
    "cosine_similarity = lambda vec1,vec2: 1 -spatial.distance.cosine(vec1,vec2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write an expression for vector arithmetic\n",
    "# For example: new_vector = word1 - word2 + word3\n",
    "lion=nlp.vocab['lion'].vector\n",
    "man=nlp.vocab['man'].vector\n",
    "woman=nlp.vocab['woman'].vector\n",
    "\n",
    "new_vector = lion - man +woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the top ten closest vectors in the vocabulary to the result of the expression above\n",
    "computed_similarities = []\n",
    "\n",
    "#for all word in nlp.vocab\n",
    "\n",
    "for word in nlp.vocab:\n",
    "    if word.has_vector:\n",
    "        if word.is_lower:\n",
    "            if word.is_alpha:\n",
    "                similarity=cosine_similarity(word.vector,new_vector)\n",
    "                computed_similarities.append((word,similarity))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<spacy.lexeme.Lexeme at 0x1bc519e0a00>, 0.7906613349914551),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ced80>, 0.5402908325195312),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce9c0>, 0.5236889719963074),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0600>, 0.4630261957645416),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e02c0>, 0.402625173330307),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e00c0>, 0.39202508330345154),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce240>, 0.24180446565151215),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cecc0>, 0.23709988594055176),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ceb40>, 0.22787579894065857),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0100>, 0.22097858786582947),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cea00>, 0.2083979696035385),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dd880>, 0.2055392861366272),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0880>, 0.2049071192741394),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cea80>, 0.1899579018354416),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc42bcda80>, 0.18488773703575134),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e03c0>, 0.17610269784927368),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ddb40>, 0.17535029351711273),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cefc0>, 0.1751156747341156),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ceb00>, 0.17314694821834564),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0400>, 0.17268796265125275),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dd600>, 0.1713191121816635),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dda80>, 0.17095907032489777),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cea40>, 0.16638006269931793),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0280>, 0.16503818333148956),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce900>, 0.16433992981910706),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0b00>, 0.16259725391864777),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ceec0>, 0.16000813245773315),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e07c0>, 0.15971288084983826),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ddfc0>, 0.15938590466976166),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0380>, 0.15903864800930023),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce340>, 0.15755504369735718),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0540>, 0.15593570470809937),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc42bcdb40>, 0.1549443155527115),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc42bcdc80>, 0.1548621505498886),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce940>, 0.15092168748378754),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0a80>, 0.14717715978622437),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dd900>, 0.14446517825126648),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0b40>, 0.14419545233249664),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cef00>, 0.1440218836069107),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0480>, 0.14365136623382568),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0440>, 0.14278839528560638),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dd9c0>, 0.14263758063316345),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e05c0>, 0.1421467363834381),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce180>, 0.141765296459198),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e09c0>, 0.14126919209957123),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ced00>, 0.14121593534946442),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cee40>, 0.14041438698768616),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce1c0>, 0.1358967125415802),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dd840>, 0.13587409257888794),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0200>, 0.13575440645217896),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0140>, 0.1346188336610794),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0640>, 0.13324756920337677),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e01c0>, 0.13260819017887115),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0040>, 0.13144205510616302),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ceb80>, 0.13133040070533752),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce200>, 0.1298009306192398),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce800>, 0.12935076653957367),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0740>, 0.1247120127081871),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce7c0>, 0.12414075434207916),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cec80>, 0.12255118042230606),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cedc0>, 0.1225099191069603),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce840>, 0.12190242111682892),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc42bcdb80>, 0.11835785955190659),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dd500>, 0.11798849701881409),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce740>, 0.117439866065979),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0bc0>, 0.11381964385509491),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cebc0>, 0.11377757042646408),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0980>, 0.11295543611049652),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0300>, 0.11169309169054031),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0a40>, 0.10695075243711472),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cec00>, 0.10198698192834854),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dda40>, 0.09772222489118576),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0180>, 0.09541423618793488),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0340>, 0.09493940323591232),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0680>, 0.0944560319185257),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cec40>, 0.09441059827804565),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce780>, 0.09391026198863983),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dd480>, 0.09004777669906616),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ddac0>, 0.08647716045379639),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0780>, 0.08540305495262146),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce880>, 0.08522927016019821),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dd700>, 0.08478781580924988),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cee80>, 0.08422345668077469),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0840>, 0.08386842161417007),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0080>, 0.07721611857414246),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce980>, 0.06632434576749802),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0240>, 0.06603699922561646),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dd800>, 0.06541014462709427),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ce5c0>, 0.06505303084850311),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0900>, 0.0582985021173954),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e06c0>, 0.057056475430727005),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0580>, 0.056225650012493134),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cef80>, 0.05235768109560013),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cee00>, 0.049810122698545456),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0700>, 0.04682179167866707),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0ac0>, 0.04621092975139618),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e04c0>, 0.044262051582336426),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dd4c0>, 0.038726966828107834),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dd8c0>, 0.03614358603954315),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dda00>, 0.03458040580153465),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0500>, 0.03296050429344177),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519cef40>, 0.03051808662712574),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ceac0>, 0.027755454182624817),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0800>, 0.01986517384648323),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dd440>, 0.01853518933057785),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc42bcd980>, 0.0021996968425810337),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519ced40>, -0.019524363800883293),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519e0940>, -0.039243362843990326),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dd980>, -0.04311688244342804),\n",
       " (<spacy.lexeme.Lexeme at 0x1bc519dd780>, -0.04322415217757225)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_similarities = sorted(computed_similarities,key=lambda item:-item[1])\n",
    "computed_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lion', 'woman', 'wolf', 'cat', 'dog', 'she', 'dare', 'a', 'ca', 'when', 'who', 'does', 'i', 'how', 'where', 'not', 'must', 'or', 'could', 'sha', 'would', 'might', 'why', 'man', 'you', 'and', 'there', 'that', 'had', 'did', 'they', 's', 'is', 'it', 'was', 'should', 'do', 'let', 'got', 'have', 'has', 'ought', 'am', 'he', 'wo', 't', 'u', 'this', 'co', 'what', 'may', 'can', 'coz', 'j', 'cuz', 'll', 'cause', 'on', 'c', 'were', 'l', 'need', 'e', 'cos', 'f', 've', 'those', 'ai', 'lovin', 'are', 'space', 'these', 'all', 're', 'we', 'h', 'd', 'k', 'b', 'x', 'm', 'r', 'q', 'o', 'bout', 'y', 'nothin', 'g', 'nt', 'z', 'n', 'p', 'v', 'havin', 'em', 'goin', 'vs', 'doin', 'somethin', 'pm', 'ol', 'gon', 'ta', 'na', 'w', 'nuthin', 'nuff', 'ö', 'ä', 'ü']\n"
     ]
    }
   ],
   "source": [
    "print([t[0].text for t in computed_similarities])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHALLENGE: Write a function that takes in 3 strings, performs a-b+c arithmetic, and returns a top-ten result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_math(a,b,c):\n",
    "    a=nlp.vocab[a].vector\n",
    "    b=nlp.vocab[b].vector\n",
    "    c=nlp.vocab[c].vector\n",
    "    \n",
    "    new_vector=a-b+c\n",
    "    \n",
    "    computed_similarities=[]\n",
    "    \n",
    "    for word in nlp.vocab:\n",
    "        if word.has_vector:\n",
    "            if word.is_lower:\n",
    "                if word.is_alpha:\n",
    "                    similarity=cosine_similarity(word.vector,new_vector)\n",
    "                    computed_similarities.append((word,similarity))\n",
    "                    \n",
    "    \n",
    "    computed_similarities=sorted(computed_similarities,key= lambda item:-item[1])\n",
    "    \n",
    "    top_ten_results= [ t[0].text for t in computed_similarities[:10]]\n",
    "    return top_ten_results\n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['king', 'woman', 'she', 'lion', 'who', 'wolf', 'when', 'dare', 'cat', 'was']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function on known words:\n",
    "vector_math('king','man','woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task #2: Perform VADER Sentiment Analysis on your own review\n",
    "Write code that returns a set of SentimentIntensityAnalyzer polarity scores based on your own written review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SentimentIntensityAnalyzer and create an sid object\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid=SentimentIntensityAnalyzer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a review as one continuous string (multiple sentences are ok)\n",
    "review = 'this is a bad movie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.538, 'neu': 0.462, 'pos': 0.0, 'compound': -0.5423}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the sid scores for your review\n",
    "sid.polarity_scores(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHALLENGE: Write a function that takes in a review and returns a score of \"Positive\", \"Negative\" or \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_rating(string):\n",
    "    review = sid.polarity_scores(string)\n",
    "    \n",
    "    if review['compound'] == 0:\n",
    "        return \"Neutral\"\n",
    "    elif review['compound'] <= 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Positive\"\n",
    "#     return review\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function on your review above:\n",
    "review_rating(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
