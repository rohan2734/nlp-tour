{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alpha-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exciting-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "#loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "specified-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')\n",
    "#creating a object of model,\n",
    "#it holds the process text,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "looking-speaker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "#spacy, will parse the doc, into seperate components, called tokens(\n",
    "#each word is a token)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_,token.dep_)#token.pos (prints numbers for par\n",
    "    #ts of speech)\n",
    "    #dep_ , it will give more information, it is snytactic dependancy, we will\n",
    "    #see it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chief-trainer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla 96\n",
      "is 87\n",
      "looking 100\n",
      "at 85\n",
      "buying 100\n",
      "U.S. 96\n",
      "startup 92\n",
      "for 85\n",
      "$ 99\n",
      "6 93\n",
      "million 93\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,token.pos_)\n",
    "    #for parts of speech, you can use underscore at end of pos, token.pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "potential-runner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2e6777f8450>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2e6778439a0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x2e6777e5820>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2e6777e5ac0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x2e677882880>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2e6778be140>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline object\n",
    "nlp.pipeline\n",
    "#when we run our nlp,our text enters enters into  a processing pipeline,\n",
    "#that first breaks down our text.  and then it performs, seris of operations\n",
    "#the tok2vec,.. pr \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "french-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "roman-equation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "n't PART neg\n",
      "looking VERB ROOT\n",
      "for ADP prep\n",
      "startups NOUN pobj\n",
      "anymore ADV advmod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "#tokenisation\n",
    "#for processing any texts, is to split up all the words or component parts into\n",
    "#tokens\n",
    "#and these tokens, are anootated, inside doc objects, to contain the \n",
    "#scripted information\n",
    "\n",
    "doc2 = nlp(u\"Tesla isn't looking for startups anymore.\")\n",
    "for token in doc2:\n",
    "    print(token.text,token.pos_,token.dep_)\n",
    "    \n",
    "#extended whitespace, will also become token\n",
    "#n't is also a token\n",
    "#. perios is also a token\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "convertible-consortium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AUX'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[1].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "potential-keyboard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nsubj'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "strong-prediction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spacy.explain('PROPN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "economic-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bulgarian-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_quote = doc3[16:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "presidential-light",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_quote) #this is a span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "absolute-dialogue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc3)#thisis a doc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "owned-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u\"This is the first sentence.This is another sentence.This is the lastsentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "communist-celebrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the lastsentence\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc4.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "arabic-queue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[7].is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-physiology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
