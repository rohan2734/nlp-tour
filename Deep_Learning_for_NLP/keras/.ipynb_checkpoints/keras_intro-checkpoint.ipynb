{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "professional-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "restricted-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataset, it is built in the scikit learn\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "forced-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "empirical-airplane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris)\n",
    "#it is a special bunch object returned by the scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "detailed-hurricane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "blind-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "positive-packet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "#- sepal length in cm\n",
    "        #- sepal width in cm\n",
    "        # petal length in cm\n",
    "        #- petal width in cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adjusted-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "political-restriction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n",
    "#class 0 , class 1, class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "compound-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because  of the way keras and neural networks , we want the data to convert into\n",
    "#categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "drawn-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 0 ---> [1,0,0]  \n",
    "# class 1 ---> [0,1,0]  \n",
    "# class 2 ---> [0,0,1]\n",
    "\n",
    "# this is 1 hardcoding, and we will be able to do this easily, with built in functions in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fixed-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "actual-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "attached-wales",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adopted-aruba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "understanding-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can continue on to split the data intro training and testing data for keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sorted-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "yellow-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "constant-piece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "X_test\n",
    "y_train\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "common-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to scale or standardize the data\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "careful-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it makes all the values fit between a range like 0 to 1, or -1 to 1, \n",
    "#it essentially divides all the values with the max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "comparative-school",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25.5 ,  0.75,  1.  ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([510,15,20])/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "happy-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_object = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "intimate-bible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the scalar object to training data, because we dont want to cheat, or asusme the prior knowledge test data\n",
    "scalar_object.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "after-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#then we are going to create sclaed versions of our training data\n",
    "scalar_X_train = scalar_object.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "severe-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scalar_object.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "remarkable-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_X_test\n",
    "#now we have the sclaed versions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "peaceful-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we will build the network with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "earned-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "hydraulic-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Dense(8,input_dim=4,activation='relu'))#input layer\n",
    "#units=8 (8 neurons) ( we chose a multiple of number of features), we are expecting 4 features, activation function is reactified linear unit\n",
    "model.add(Dense(8,input_dim=4,activation='relu'))\n",
    "model.add(Dense(3,activation='softmax'))#output layer#[0.2,0.3,0.5]\n",
    "\n",
    "# at the end, the neuron will return 30% chances for the first index value, 30% for second and 40% for the remaining\n",
    "#we compile our model at the end\n",
    "# we choose sort of loss, it depends on what you choose,\n",
    "#we are doing categorical process, so we will say, categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "executive-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "modern-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 139\n",
      "Trainable params: 139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "horizontal-embassy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 - 0s - loss: 1.2632 - accuracy: 0.3100\n",
      "Epoch 2/150\n",
      "4/4 - 0s - loss: 1.2246 - accuracy: 0.3100\n",
      "Epoch 3/150\n",
      "4/4 - 0s - loss: 1.1943 - accuracy: 0.3000\n",
      "Epoch 4/150\n",
      "4/4 - 0s - loss: 1.1660 - accuracy: 0.2900\n",
      "Epoch 5/150\n",
      "4/4 - 0s - loss: 1.1408 - accuracy: 0.2700\n",
      "Epoch 6/150\n",
      "4/4 - 0s - loss: 1.1182 - accuracy: 0.2500\n",
      "Epoch 7/150\n",
      "4/4 - 0s - loss: 1.0965 - accuracy: 0.3200\n",
      "Epoch 8/150\n",
      "4/4 - 0s - loss: 1.0781 - accuracy: 0.4400\n",
      "Epoch 9/150\n",
      "4/4 - 0s - loss: 1.0595 - accuracy: 0.5300\n",
      "Epoch 10/150\n",
      "4/4 - 0s - loss: 1.0441 - accuracy: 0.5300\n",
      "Epoch 11/150\n",
      "4/4 - 0s - loss: 1.0283 - accuracy: 0.5200\n",
      "Epoch 12/150\n",
      "4/4 - 0s - loss: 1.0145 - accuracy: 0.5400\n",
      "Epoch 13/150\n",
      "4/4 - 0s - loss: 1.0024 - accuracy: 0.5500\n",
      "Epoch 14/150\n",
      "4/4 - 0s - loss: 0.9905 - accuracy: 0.5700\n",
      "Epoch 15/150\n",
      "4/4 - 0s - loss: 0.9791 - accuracy: 0.6100\n",
      "Epoch 16/150\n",
      "4/4 - 0s - loss: 0.9685 - accuracy: 0.6200\n",
      "Epoch 17/150\n",
      "4/4 - 0s - loss: 0.9581 - accuracy: 0.6200\n",
      "Epoch 18/150\n",
      "4/4 - 0s - loss: 0.9485 - accuracy: 0.6200\n",
      "Epoch 19/150\n",
      "4/4 - 0s - loss: 0.9393 - accuracy: 0.6200\n",
      "Epoch 20/150\n",
      "4/4 - 0s - loss: 0.9300 - accuracy: 0.6400\n",
      "Epoch 21/150\n",
      "4/4 - 0s - loss: 0.9208 - accuracy: 0.6400\n",
      "Epoch 22/150\n",
      "4/4 - 0s - loss: 0.9117 - accuracy: 0.6400\n",
      "Epoch 23/150\n",
      "4/4 - 0s - loss: 0.9027 - accuracy: 0.6400\n",
      "Epoch 24/150\n",
      "4/4 - 0s - loss: 0.8937 - accuracy: 0.6400\n",
      "Epoch 25/150\n",
      "4/4 - 0s - loss: 0.8848 - accuracy: 0.6400\n",
      "Epoch 26/150\n",
      "4/4 - 0s - loss: 0.8757 - accuracy: 0.6500\n",
      "Epoch 27/150\n",
      "4/4 - 0s - loss: 0.8669 - accuracy: 0.6500\n",
      "Epoch 28/150\n",
      "4/4 - 0s - loss: 0.8581 - accuracy: 0.6500\n",
      "Epoch 29/150\n",
      "4/4 - 0s - loss: 0.8498 - accuracy: 0.6500\n",
      "Epoch 30/150\n",
      "4/4 - 0s - loss: 0.8417 - accuracy: 0.6500\n",
      "Epoch 31/150\n",
      "4/4 - 0s - loss: 0.8336 - accuracy: 0.6500\n",
      "Epoch 32/150\n",
      "4/4 - 0s - loss: 0.8255 - accuracy: 0.6500\n",
      "Epoch 33/150\n",
      "4/4 - 0s - loss: 0.8178 - accuracy: 0.6500\n",
      "Epoch 34/150\n",
      "4/4 - 0s - loss: 0.8094 - accuracy: 0.6500\n",
      "Epoch 35/150\n",
      "4/4 - 0s - loss: 0.8017 - accuracy: 0.6500\n",
      "Epoch 36/150\n",
      "4/4 - 0s - loss: 0.7943 - accuracy: 0.6500\n",
      "Epoch 37/150\n",
      "4/4 - 0s - loss: 0.7870 - accuracy: 0.6500\n",
      "Epoch 38/150\n",
      "4/4 - 0s - loss: 0.7796 - accuracy: 0.6500\n",
      "Epoch 39/150\n",
      "4/4 - 0s - loss: 0.7725 - accuracy: 0.6500\n",
      "Epoch 40/150\n",
      "4/4 - 0s - loss: 0.7654 - accuracy: 0.6500\n",
      "Epoch 41/150\n",
      "4/4 - 0s - loss: 0.7583 - accuracy: 0.6500\n",
      "Epoch 42/150\n",
      "4/4 - 0s - loss: 0.7513 - accuracy: 0.6500\n",
      "Epoch 43/150\n",
      "4/4 - 0s - loss: 0.7444 - accuracy: 0.6500\n",
      "Epoch 44/150\n",
      "4/4 - 0s - loss: 0.7379 - accuracy: 0.6500\n",
      "Epoch 45/150\n",
      "4/4 - 0s - loss: 0.7306 - accuracy: 0.6500\n",
      "Epoch 46/150\n",
      "4/4 - 0s - loss: 0.7240 - accuracy: 0.6500\n",
      "Epoch 47/150\n",
      "4/4 - 0s - loss: 0.7168 - accuracy: 0.6500\n",
      "Epoch 48/150\n",
      "4/4 - 0s - loss: 0.7103 - accuracy: 0.6500\n",
      "Epoch 49/150\n",
      "4/4 - 0s - loss: 0.7034 - accuracy: 0.6500\n",
      "Epoch 50/150\n",
      "4/4 - 0s - loss: 0.6973 - accuracy: 0.6500\n",
      "Epoch 51/150\n",
      "4/4 - 0s - loss: 0.6911 - accuracy: 0.6500\n",
      "Epoch 52/150\n",
      "4/4 - 0s - loss: 0.6858 - accuracy: 0.6500\n",
      "Epoch 53/150\n",
      "4/4 - 0s - loss: 0.6800 - accuracy: 0.6500\n",
      "Epoch 54/150\n",
      "4/4 - 0s - loss: 0.6736 - accuracy: 0.6500\n",
      "Epoch 55/150\n",
      "4/4 - 0s - loss: 0.6669 - accuracy: 0.6500\n",
      "Epoch 56/150\n",
      "4/4 - 0s - loss: 0.6606 - accuracy: 0.6500\n",
      "Epoch 57/150\n",
      "4/4 - 0s - loss: 0.6542 - accuracy: 0.6500\n",
      "Epoch 58/150\n",
      "4/4 - 0s - loss: 0.6484 - accuracy: 0.6500\n",
      "Epoch 59/150\n",
      "4/4 - 0s - loss: 0.6424 - accuracy: 0.6500\n",
      "Epoch 60/150\n",
      "4/4 - 0s - loss: 0.6369 - accuracy: 0.6500\n",
      "Epoch 61/150\n",
      "4/4 - 0s - loss: 0.6317 - accuracy: 0.6500\n",
      "Epoch 62/150\n",
      "4/4 - 0s - loss: 0.6266 - accuracy: 0.6500\n",
      "Epoch 63/150\n",
      "4/4 - 0s - loss: 0.6206 - accuracy: 0.6500\n",
      "Epoch 64/150\n",
      "4/4 - 0s - loss: 0.6153 - accuracy: 0.6500\n",
      "Epoch 65/150\n",
      "4/4 - 0s - loss: 0.6100 - accuracy: 0.6500\n",
      "Epoch 66/150\n",
      "4/4 - 0s - loss: 0.6049 - accuracy: 0.6500\n",
      "Epoch 67/150\n",
      "4/4 - 0s - loss: 0.6001 - accuracy: 0.6500\n",
      "Epoch 68/150\n",
      "4/4 - 0s - loss: 0.5955 - accuracy: 0.6500\n",
      "Epoch 69/150\n",
      "4/4 - 0s - loss: 0.5910 - accuracy: 0.6500\n",
      "Epoch 70/150\n",
      "4/4 - 0s - loss: 0.5864 - accuracy: 0.6500\n",
      "Epoch 71/150\n",
      "4/4 - 0s - loss: 0.5819 - accuracy: 0.6500\n",
      "Epoch 72/150\n",
      "4/4 - 0s - loss: 0.5781 - accuracy: 0.6500\n",
      "Epoch 73/150\n",
      "4/4 - 0s - loss: 0.5738 - accuracy: 0.6700\n",
      "Epoch 74/150\n",
      "4/4 - 0s - loss: 0.5695 - accuracy: 0.6700\n",
      "Epoch 75/150\n",
      "4/4 - 0s - loss: 0.5656 - accuracy: 0.6800\n",
      "Epoch 76/150\n",
      "4/4 - 0s - loss: 0.5614 - accuracy: 0.6800\n",
      "Epoch 77/150\n",
      "4/4 - 0s - loss: 0.5578 - accuracy: 0.6800\n",
      "Epoch 78/150\n",
      "4/4 - 0s - loss: 0.5540 - accuracy: 0.6800\n",
      "Epoch 79/150\n",
      "4/4 - 0s - loss: 0.5500 - accuracy: 0.6800\n",
      "Epoch 80/150\n",
      "4/4 - 0s - loss: 0.5464 - accuracy: 0.6800\n",
      "Epoch 81/150\n",
      "4/4 - 0s - loss: 0.5430 - accuracy: 0.6600\n",
      "Epoch 82/150\n",
      "4/4 - 0s - loss: 0.5400 - accuracy: 0.6500\n",
      "Epoch 83/150\n",
      "4/4 - 0s - loss: 0.5362 - accuracy: 0.6500\n",
      "Epoch 84/150\n",
      "4/4 - 0s - loss: 0.5330 - accuracy: 0.6500\n",
      "Epoch 85/150\n",
      "4/4 - 0s - loss: 0.5287 - accuracy: 0.6700\n",
      "Epoch 86/150\n",
      "4/4 - 0s - loss: 0.5261 - accuracy: 0.6800\n",
      "Epoch 87/150\n",
      "4/4 - 0s - loss: 0.5241 - accuracy: 0.7100\n",
      "Epoch 88/150\n",
      "4/4 - 0s - loss: 0.5217 - accuracy: 0.7300\n",
      "Epoch 89/150\n",
      "4/4 - 0s - loss: 0.5189 - accuracy: 0.7300\n",
      "Epoch 90/150\n",
      "4/4 - 0s - loss: 0.5156 - accuracy: 0.7300\n",
      "Epoch 91/150\n",
      "4/4 - 0s - loss: 0.5131 - accuracy: 0.7300\n",
      "Epoch 92/150\n",
      "4/4 - 0s - loss: 0.5101 - accuracy: 0.7200\n",
      "Epoch 93/150\n",
      "4/4 - 0s - loss: 0.5081 - accuracy: 0.7200\n",
      "Epoch 94/150\n",
      "4/4 - 0s - loss: 0.5052 - accuracy: 0.7000\n",
      "Epoch 95/150\n",
      "4/4 - 0s - loss: 0.5028 - accuracy: 0.7000\n",
      "Epoch 96/150\n",
      "4/4 - 0s - loss: 0.5002 - accuracy: 0.7000\n",
      "Epoch 97/150\n",
      "4/4 - 0s - loss: 0.4981 - accuracy: 0.7200\n",
      "Epoch 98/150\n",
      "4/4 - 0s - loss: 0.4959 - accuracy: 0.7300\n",
      "Epoch 99/150\n",
      "4/4 - 0s - loss: 0.4934 - accuracy: 0.7300\n",
      "Epoch 100/150\n",
      "4/4 - 0s - loss: 0.4911 - accuracy: 0.7300\n",
      "Epoch 101/150\n",
      "4/4 - 0s - loss: 0.4888 - accuracy: 0.7300\n",
      "Epoch 102/150\n",
      "4/4 - 0s - loss: 0.4868 - accuracy: 0.7300\n",
      "Epoch 103/150\n",
      "4/4 - 0s - loss: 0.4843 - accuracy: 0.7300\n",
      "Epoch 104/150\n",
      "4/4 - 0s - loss: 0.4822 - accuracy: 0.7300\n",
      "Epoch 105/150\n",
      "4/4 - 0s - loss: 0.4801 - accuracy: 0.7300\n",
      "Epoch 106/150\n",
      "4/4 - 0s - loss: 0.4781 - accuracy: 0.7300\n",
      "Epoch 107/150\n",
      "4/4 - 0s - loss: 0.4763 - accuracy: 0.7300\n",
      "Epoch 108/150\n",
      "4/4 - 0s - loss: 0.4742 - accuracy: 0.7200\n",
      "Epoch 109/150\n",
      "4/4 - 0s - loss: 0.4723 - accuracy: 0.7200\n",
      "Epoch 110/150\n",
      "4/4 - 0s - loss: 0.4708 - accuracy: 0.7200\n",
      "Epoch 111/150\n",
      "4/4 - 0s - loss: 0.4690 - accuracy: 0.7200\n",
      "Epoch 112/150\n",
      "4/4 - 0s - loss: 0.4674 - accuracy: 0.7200\n",
      "Epoch 113/150\n",
      "4/4 - 0s - loss: 0.4657 - accuracy: 0.7200\n",
      "Epoch 114/150\n",
      "4/4 - 0s - loss: 0.4641 - accuracy: 0.7200\n",
      "Epoch 115/150\n",
      "4/4 - 0s - loss: 0.4624 - accuracy: 0.7200\n",
      "Epoch 116/150\n",
      "4/4 - 0s - loss: 0.4606 - accuracy: 0.7200\n",
      "Epoch 117/150\n",
      "4/4 - 0s - loss: 0.4588 - accuracy: 0.7200\n",
      "Epoch 118/150\n",
      "4/4 - 0s - loss: 0.4573 - accuracy: 0.7300\n",
      "Epoch 119/150\n",
      "4/4 - 0s - loss: 0.4556 - accuracy: 0.7400\n",
      "Epoch 120/150\n",
      "4/4 - 0s - loss: 0.4536 - accuracy: 0.7500\n",
      "Epoch 121/150\n",
      "4/4 - 0s - loss: 0.4522 - accuracy: 0.7900\n",
      "Epoch 122/150\n",
      "4/4 - 0s - loss: 0.4508 - accuracy: 0.8100\n",
      "Epoch 123/150\n",
      "4/4 - 0s - loss: 0.4494 - accuracy: 0.8000\n",
      "Epoch 124/150\n",
      "4/4 - 0s - loss: 0.4477 - accuracy: 0.8000\n",
      "Epoch 125/150\n",
      "4/4 - 0s - loss: 0.4463 - accuracy: 0.7800\n",
      "Epoch 126/150\n",
      "4/4 - 0s - loss: 0.4446 - accuracy: 0.7700\n",
      "Epoch 127/150\n",
      "4/4 - 0s - loss: 0.4432 - accuracy: 0.7800\n",
      "Epoch 128/150\n",
      "4/4 - 0s - loss: 0.4417 - accuracy: 0.7800\n",
      "Epoch 129/150\n",
      "4/4 - 0s - loss: 0.4401 - accuracy: 0.7900\n",
      "Epoch 130/150\n",
      "4/4 - 0s - loss: 0.4388 - accuracy: 0.8300\n",
      "Epoch 131/150\n",
      "4/4 - 0s - loss: 0.4383 - accuracy: 0.8700\n",
      "Epoch 132/150\n",
      "4/4 - 0s - loss: 0.4370 - accuracy: 0.8900\n",
      "Epoch 133/150\n",
      "4/4 - 0s - loss: 0.4353 - accuracy: 0.8900\n",
      "Epoch 134/150\n",
      "4/4 - 0s - loss: 0.4337 - accuracy: 0.8700\n",
      "Epoch 135/150\n",
      "4/4 - 0s - loss: 0.4318 - accuracy: 0.8600\n",
      "Epoch 136/150\n",
      "4/4 - 0s - loss: 0.4306 - accuracy: 0.8800\n",
      "Epoch 137/150\n",
      "4/4 - 0s - loss: 0.4293 - accuracy: 0.8900\n",
      "Epoch 138/150\n",
      "4/4 - 0s - loss: 0.4277 - accuracy: 0.8900\n",
      "Epoch 139/150\n",
      "4/4 - 0s - loss: 0.4261 - accuracy: 0.8600\n",
      "Epoch 140/150\n",
      "4/4 - 0s - loss: 0.4248 - accuracy: 0.8400\n",
      "Epoch 141/150\n",
      "4/4 - 0s - loss: 0.4234 - accuracy: 0.8700\n",
      "Epoch 142/150\n",
      "4/4 - 0s - loss: 0.4220 - accuracy: 0.8700\n",
      "Epoch 143/150\n",
      "4/4 - 0s - loss: 0.4207 - accuracy: 0.8700\n",
      "Epoch 144/150\n",
      "4/4 - 0s - loss: 0.4193 - accuracy: 0.8600\n",
      "Epoch 145/150\n",
      "4/4 - 0s - loss: 0.4180 - accuracy: 0.8400\n",
      "Epoch 146/150\n",
      "4/4 - 0s - loss: 0.4169 - accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/150\n",
      "4/4 - 0s - loss: 0.4157 - accuracy: 0.8400\n",
      "Epoch 148/150\n",
      "4/4 - 0s - loss: 0.4141 - accuracy: 0.8600\n",
      "Epoch 149/150\n",
      "4/4 - 0s - loss: 0.4135 - accuracy: 0.8800\n",
      "Epoch 150/150\n",
      "4/4 - 0s - loss: 0.4115 - accuracy: 0.8900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c921a3dca0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scalar_X_train,y_train,epochs=150,verbose=2)\n",
    "#epoch is trunning through an entire dataset\n",
    "#verbose, is how much output u want information\n",
    "#0 it is not gonna work for anhting\n",
    "#1 for progress bar\n",
    "#2 for loss, and accuray on epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "played-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how do we predict on new unseen data, and how to evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "successful-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we first need to scale our test data, for new incoming data\n",
    "#we already done that, \n",
    "#but if we have fresh data, we have to scale the data firs,because our model \n",
    "#is trained on the scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "three-sudan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.20029887e-02, 5.15042782e-01, 4.72954214e-01],\n",
       "       [9.69126284e-01, 1.70237776e-02, 1.38499327e-02],\n",
       "       [3.04159679e-04, 2.31192693e-01, 7.68503189e-01],\n",
       "       [1.10599399e-02, 4.84448493e-01, 5.04491508e-01],\n",
       "       [5.71940420e-03, 4.38603044e-01, 5.55677533e-01],\n",
       "       [9.44424510e-01, 3.15948054e-02, 2.39806976e-02],\n",
       "       [4.27761897e-02, 5.20690680e-01, 4.36533123e-01],\n",
       "       [1.89828547e-03, 3.14816892e-01, 6.83284760e-01],\n",
       "       [7.26801297e-03, 4.16304380e-01, 5.76427579e-01],\n",
       "       [2.21258737e-02, 5.32952547e-01, 4.44921553e-01],\n",
       "       [3.69819649e-03, 3.90530825e-01, 6.05770946e-01],\n",
       "       [9.39577937e-01, 3.51316482e-02, 2.52904948e-02],\n",
       "       [9.65281844e-01, 1.93998180e-02, 1.53183425e-02],\n",
       "       [9.43926871e-01, 3.25262882e-02, 2.35468876e-02],\n",
       "       [9.78956759e-01, 1.11114290e-02, 9.93179344e-03],\n",
       "       [8.59405845e-03, 4.79255438e-01, 5.12150466e-01],\n",
       "       [1.81112159e-03, 3.35509926e-01, 6.62678897e-01],\n",
       "       [2.58250684e-02, 5.43473303e-01, 4.30701643e-01],\n",
       "       [1.59100741e-02, 5.25658369e-01, 4.58431482e-01],\n",
       "       [2.00209883e-03, 3.29304427e-01, 6.68693423e-01],\n",
       "       [9.54642057e-01, 2.57583484e-02, 1.95995308e-02],\n",
       "       [6.27003564e-03, 4.33581114e-01, 5.60148895e-01],\n",
       "       [9.60558236e-01, 2.24195290e-02, 1.70221925e-02],\n",
       "       [2.24025082e-03, 3.43920171e-01, 6.53839648e-01],\n",
       "       [8.23170820e-04, 3.34143043e-01, 6.65033758e-01],\n",
       "       [1.98220694e-03, 3.17625552e-01, 6.80392265e-01],\n",
       "       [1.96602009e-03, 3.45565587e-01, 6.52468324e-01],\n",
       "       [1.34017866e-03, 3.17104787e-01, 6.81555033e-01],\n",
       "       [9.35625434e-01, 3.79622132e-02, 2.64123362e-02],\n",
       "       [9.42299545e-01, 3.37076336e-02, 2.39927601e-02],\n",
       "       [9.74193275e-01, 1.34915933e-02, 1.23150265e-02],\n",
       "       [9.89679813e-01, 5.03214030e-03, 5.28806169e-03],\n",
       "       [8.68721213e-03, 4.74380374e-01, 5.16932428e-01],\n",
       "       [9.64863837e-01, 1.94641612e-02, 1.56720560e-02],\n",
       "       [9.55160797e-01, 2.50163358e-02, 1.98228136e-02],\n",
       "       [3.73532972e-03, 3.65254372e-01, 6.31010294e-01],\n",
       "       [9.57886502e-03, 4.83428955e-01, 5.06992161e-01],\n",
       "       [9.67432678e-01, 1.80308111e-02, 1.45364907e-02],\n",
       "       [9.73411620e-01, 1.42720407e-02, 1.23163573e-02],\n",
       "       [9.86114144e-01, 6.94246823e-03, 6.94331573e-03],\n",
       "       [5.48124639e-03, 4.09856915e-01, 5.84661841e-01],\n",
       "       [1.78509802e-02, 4.84845400e-01, 4.97303694e-01],\n",
       "       [6.60293270e-03, 4.54475939e-01, 5.38921118e-01],\n",
       "       [9.81708884e-01, 9.56289377e-03, 8.72824807e-03],\n",
       "       [9.74942744e-01, 1.35496482e-02, 1.15076164e-02],\n",
       "       [3.31312753e-02, 5.51786184e-01, 4.15082544e-01],\n",
       "       [6.14338182e-03, 4.49912935e-01, 5.43943763e-01],\n",
       "       [3.74977360e-03, 4.14495766e-01, 5.81754446e-01],\n",
       "       [8.94428603e-03, 4.72543836e-01, 5.18511891e-01],\n",
       "       [8.46974726e-04, 2.92592794e-01, 7.06560194e-01]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "banned-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we want the raw classes itself, \n",
    "predictions=model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "elder-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "official-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform y_test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "central-accordance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.argmax(axis=1)\n",
    "#it returns actual classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "perceived-personality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#becuaese\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "joined-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max value will be in the index posiiton of the corresponding class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "binary-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have preuctions, and original y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "hundred-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need to compare the predictions to the true values\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "amazing-fence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 2, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0,\n",
       "       0, 1, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "distinct-shark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19,  0,  0],\n",
       "       [ 0,  6,  9],\n",
       "       [ 0,  0, 16]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test.argmax(axis=1),predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "extreme-industry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.40      0.57        15\n",
      "           2       0.64      1.00      0.78        16\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.88      0.80      0.78        50\n",
      "weighted avg       0.88      0.82      0.80        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1),predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "specialized-investment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test.argmax(axis=1),predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "judicial-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we have evaluated on unseen data\n",
    "#now the last thing we want to do is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "hairy-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we are running a super large mode, like text generation\n",
    "#we want to save and laod our model\n",
    "model.save('myfirstmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "alert-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it saves all the weights, in that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "duplicate-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "handmade-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=load_model('myfirstmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "brown-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to be careful with the saving , it can override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "apart-delaware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 2, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0,\n",
       "       0, 1, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "physical-transcript",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52941176,  0.36363636,  0.64285714,  0.45833333],\n",
       "       [ 0.41176471,  0.81818182,  0.10714286,  0.08333333],\n",
       "       [ 1.        ,  0.27272727,  1.03571429,  0.91666667],\n",
       "       [ 0.5       ,  0.40909091,  0.60714286,  0.58333333],\n",
       "       [ 0.73529412,  0.36363636,  0.66071429,  0.54166667],\n",
       "       [ 0.32352941,  0.63636364,  0.07142857,  0.125     ],\n",
       "       [ 0.38235294,  0.40909091,  0.44642857,  0.5       ],\n",
       "       [ 0.76470588,  0.5       ,  0.71428571,  0.91666667],\n",
       "       [ 0.55882353,  0.09090909,  0.60714286,  0.58333333],\n",
       "       [ 0.44117647,  0.31818182,  0.5       ,  0.45833333],\n",
       "       [ 0.64705882,  0.54545455,  0.71428571,  0.79166667],\n",
       "       [ 0.14705882,  0.45454545,  0.05357143,  0.        ],\n",
       "       [ 0.35294118,  0.68181818,  0.03571429,  0.04166667],\n",
       "       [ 0.17647059,  0.5       ,  0.07142857,  0.        ],\n",
       "       [ 0.23529412,  0.81818182,  0.07142857,  0.08333333],\n",
       "       [ 0.58823529,  0.59090909,  0.64285714,  0.625     ],\n",
       "       [ 0.64705882,  0.45454545,  0.83928571,  0.875     ],\n",
       "       [ 0.38235294,  0.22727273,  0.5       ,  0.41666667],\n",
       "       [ 0.41176471,  0.36363636,  0.60714286,  0.5       ],\n",
       "       [ 0.61764706,  0.36363636,  0.80357143,  0.875     ],\n",
       "       [ 0.11764706,  0.54545455,  0.08928571,  0.04166667],\n",
       "       [ 0.52941176,  0.45454545,  0.67857143,  0.70833333],\n",
       "       [ 0.20588235,  0.63636364,  0.08928571,  0.125     ],\n",
       "       [ 0.61764706,  0.36363636,  0.80357143,  0.83333333],\n",
       "       [ 1.05882353,  0.81818182,  0.94642857,  0.79166667],\n",
       "       [ 0.70588235,  0.45454545,  0.73214286,  0.91666667],\n",
       "       [ 0.70588235,  0.22727273,  0.83928571,  0.70833333],\n",
       "       [ 0.73529412,  0.54545455,  0.85714286,  0.91666667],\n",
       "       [ 0.14705882,  0.45454545,  0.05357143,  0.08333333],\n",
       "       [ 0.14705882,  0.5       ,  0.08928571,  0.04166667],\n",
       "       [ 0.08823529,  0.72727273, -0.01785714,  0.04166667],\n",
       "       [ 0.41176471,  1.09090909,  0.07142857,  0.125     ],\n",
       "       [ 0.70588235,  0.5       ,  0.58928571,  0.54166667],\n",
       "       [ 0.14705882,  0.63636364,  0.08928571,  0.04166667],\n",
       "       [ 0.02941176,  0.54545455,  0.03571429,  0.04166667],\n",
       "       [ 0.58823529,  0.22727273,  0.69642857,  0.75      ],\n",
       "       [ 0.61764706,  0.54545455,  0.60714286,  0.58333333],\n",
       "       [ 0.26470588,  0.68181818,  0.07142857,  0.04166667],\n",
       "       [ 0.20588235,  0.72727273,  0.05357143,  0.04166667],\n",
       "       [ 0.26470588,  0.95454545,  0.07142857,  0.        ],\n",
       "       [ 0.44117647,  0.31818182,  0.71428571,  0.75      ],\n",
       "       [ 0.5       ,  0.63636364,  0.60714286,  0.625     ],\n",
       "       [ 0.70588235,  0.5       ,  0.64285714,  0.58333333],\n",
       "       [ 0.32352941,  0.86363636,  0.03571429,  0.125     ],\n",
       "       [ 0.32352941,  0.77272727,  0.07142857,  0.04166667],\n",
       "       [ 0.35294118,  0.18181818,  0.46428571,  0.375     ],\n",
       "       [ 0.58823529,  0.36363636,  0.71428571,  0.58333333],\n",
       "       [ 0.61764706,  0.5       ,  0.78571429,  0.70833333],\n",
       "       [ 0.67647059,  0.45454545,  0.58928571,  0.54166667],\n",
       "       [ 0.85294118,  0.72727273,  0.89285714,  1.        ]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-information",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
