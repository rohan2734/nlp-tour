{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "outstanding-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adult-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp  = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "spiritual-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"This is the first sentence. This is another sentence. This is the last sentence \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "united-optics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence\n"
     ]
    }
   ],
   "source": [
    "#doc.sents is a generator\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "front-alert",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-55463d493a15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#it generates the sentences, instead of saving them, for saving memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#it generates the sentences, instead of saving them, for saving memory\n",
    "doc.sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we want to do that doc.sents[0]\n",
    "#we pass it into the list\n",
    "list(doc.sents)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(list(doc.sents)[0])\n",
    "#these are spacy span objects, these are not normal strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy is good ad seperating sentences , based on start of the sentence or the end of the sentence\n",
    "#how ever, we might have  a custom dataset, and we want to segment based on few custom rules, like based on a semi colon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'\"Management is doing the right things; leadership is doing the right things.\"-Peter Drucker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "competent-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a new rule to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "thirty-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#previously we seperated on the basis of periods and white spaces to see the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "neither-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a sengmentation rule\n",
    "\n",
    "# @Language.component('set_custom_boundaries')\n",
    "def set_custom_boundaries(doc):\n",
    "    doc.is_parsed = True\n",
    "#     for token in doc:\n",
    "    for token in doc[:-1]:\n",
    "#         print(token)\n",
    "#         print(token.i)\n",
    "        if token.text == ';':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "        \n",
    "# set_custom_boundaires(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sublime-estimate",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <function set_custom_boundaries at 0x000001D3C640C790> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-40806c5fac6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# @Language.component(\"set_custom_boundaries\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_custom_boundaries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbefore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nplenv\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    746\u001b[0m             \u001b[0mbad_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE966\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbad_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfactory_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <function set_custom_boundaries at 0x000001D3C640C790> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "# #\n",
    "# @Language.component(\"set_custom_boundaries\")\n",
    "\n",
    "nlp.add_pipe(set_custom_boundaries,before='parser')\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fiscal-bikini",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is the first sentence. This is another sentence. This is the last"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[:-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "divine-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'\"Management is doing the right things; leadership is doing the right things.\"-Peter Drucker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "reserved-verification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing the right things; leadership is doing the right things.\n",
      "\"-Peter\n",
      "Drucker\n"
     ]
    }
   ],
   "source": [
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "automotive-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the sengmentation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "palestinian-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sealed-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload the english library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fancy-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "myString = u\"This is a sentence. This is another .\\n\\nThis is a  \\nthird sentence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "annual-intro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence. This is another .\n",
      "\n",
      "This is a  \n",
      "third sentence\n"
     ]
    }
   ],
   "source": [
    "print(myString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "smaller-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we might want to define a '/n 'as a line break, instead of period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "golden-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the default behaviour\n",
    "doc = nlp(myString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "sealed-softball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is another .\n",
      "\n",
      "\n",
      "\n",
      "This is a  \n",
      "third sentence\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "atmospheric-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SentenceSegmenter' from 'spacy.pipeline' (C:\\Users\\Hp\\anaconda3\\envs\\nplenv\\lib\\site-packages\\spacy\\pipeline\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-538101332913>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentenceSegmenter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SentenceSegmenter' from 'spacy.pipeline' (C:\\Users\\Hp\\anaconda3\\envs\\nplenv\\lib\\site-packages\\spacy\\pipeline\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from spacy.pipeline import SentenceSegmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-tamil",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-shooting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-joining",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-wichita",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
