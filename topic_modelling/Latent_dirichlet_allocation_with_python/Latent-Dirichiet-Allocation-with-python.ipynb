{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "theoretical-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "friendly-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "npr= pd.read_csv('npr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "infrared-jaguar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article\n",
       "0  In the Washington of 2016, even when the polic...\n",
       "1    Donald Trump has used Twitter  —   his prefe...\n",
       "2    Donald Trump is unabashedly praising Russian...\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...\n",
       "4  From photography, illustration and video, to d..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "trying-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we only have information, on the article, text, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "separated-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we dont have any labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ranging-structure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11992"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# npr['Article'][0]\n",
    "len(npr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "adult-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we dont know is, what actual topics these articles belong to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "inappropriate-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to run little bit of preprocessing before LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "secondary-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "breeding-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(max_df=0.9,min_df=2,stop_words='english')\n",
    "#we need to get rid of words, which have high document frequency\n",
    "# in simple way, gets rid of words, which are common in documents\n",
    "#so we pass max_df=0.9\n",
    "\n",
    "#words that show, up minimum number of times = 2 ,\n",
    "#this says that minimum number of frequency of words should be atleast 2 in doucments\n",
    "\n",
    "#we can also remove stop words, by adding the stop_words argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "excellent-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need to apply this , and fit transform for this article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "forward-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we cant do , train_test_split, because this is unsuoervised learning\n",
    "#since we dont have any labels\n",
    "# so we are going to do fit transform to the entire article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "medium-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm=cv.fit_transform(npr['Article'])\n",
    "#dtm (document term matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "guided-matter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 53112)\t2\n",
      "  (0, 436)\t3\n",
      "  (0, 37382)\t2\n",
      "  (0, 5867)\t1\n",
      "  (0, 37411)\t2\n",
      "  (0, 43740)\t1\n",
      "  (0, 54403)\t3\n",
      "  (0, 44460)\t2\n",
      "  (0, 28875)\t3\n",
      "  (0, 44648)\t1\n",
      "  (0, 16578)\t1\n",
      "  (0, 12950)\t1\n",
      "  (0, 604)\t1\n",
      "  (0, 38079)\t6\n",
      "  (0, 34145)\t15\n",
      "  (0, 32459)\t1\n",
      "  (0, 42732)\t1\n",
      "  (0, 42390)\t9\n",
      "  (0, 2437)\t2\n",
      "  (0, 25508)\t5\n",
      "  (0, 16123)\t4\n",
      "  (0, 26752)\t3\n",
      "  (0, 10646)\t1\n",
      "  (0, 41011)\t4\n",
      "  (0, 29070)\t1\n",
      "  :\t:\n",
      "  (11991, 4315)\t1\n",
      "  (11991, 28887)\t1\n",
      "  (11991, 32585)\t1\n",
      "  (11991, 50599)\t1\n",
      "  (11991, 9067)\t1\n",
      "  (11991, 38652)\t1\n",
      "  (11991, 47768)\t2\n",
      "  (11991, 33536)\t1\n",
      "  (11991, 16527)\t1\n",
      "  (11991, 41081)\t1\n",
      "  (11991, 14611)\t1\n",
      "  (11991, 28356)\t1\n",
      "  (11991, 35785)\t1\n",
      "  (11991, 33620)\t14\n",
      "  (11991, 7316)\t1\n",
      "  (11991, 45088)\t1\n",
      "  (11991, 22720)\t1\n",
      "  (11991, 51838)\t1\n",
      "  (11991, 37235)\t1\n",
      "  (11991, 49654)\t1\n",
      "  (11991, 15275)\t1\n",
      "  (11991, 53567)\t1\n",
      "  (11991, 12752)\t1\n",
      "  (11991, 20202)\t1\n",
      "  (11991, 47633)\t11\n"
     ]
    }
   ],
   "source": [
    "dtm\n",
    "#returns  a sparse matrix\n",
    "print(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "persistent-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need to do LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "underlying-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "framed-reach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(n_components=7, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "LDA = LatentDirichletAllocation( n_components=7 , random_state=42)\n",
    "# n_components=7 , 7 general topics\n",
    "print(LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "unavailable-content",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=7, random_state=42)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "extensive-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA, is an iterative words\n",
    "#it is going to keep updating the weights of the words , and topics, until they are \n",
    "#stabilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "innocent-angle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54777"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grab the vocabulary of the words\n",
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "generic-devon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bathrooms'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cv.get_feature_names())\n",
    "\n",
    "cv.get_feature_names()[5005]\n",
    "#we could print random words from this list\n",
    "\n",
    "import random\n",
    "\n",
    "randomr_word_id= random.randint(0,54777)\n",
    "\n",
    "cv.get_feature_names()[randomr_word_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "attached-element",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.64332806e+00, 2.38014333e+03, 1.42900522e-01, ...,\n",
       "        1.43006821e-01, 1.42902042e-01, 1.42861626e-01],\n",
       "       [2.76191749e+01, 5.36394437e+02, 1.42857148e-01, ...,\n",
       "        1.42861973e-01, 1.42857147e-01, 1.42906875e-01],\n",
       "       [7.22783888e+00, 8.24033986e+02, 1.42857148e-01, ...,\n",
       "        6.14236247e+00, 2.14061364e+00, 1.42923753e-01],\n",
       "       ...,\n",
       "       [3.11488651e+00, 3.50409655e+02, 1.42857147e-01, ...,\n",
       "        1.42859912e-01, 1.42857146e-01, 1.42866614e-01],\n",
       "       [4.61486388e+01, 5.14408600e+01, 3.14281373e+00, ...,\n",
       "        1.43107628e-01, 1.43902481e-01, 2.14271779e+00],\n",
       "       [4.93991422e-01, 4.18841042e+02, 1.42857151e-01, ...,\n",
       "        1.42857146e-01, 1.43760101e-01, 1.42866201e-01]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grab the topics\n",
    "\n",
    "len(LDA.components_)\n",
    "\n",
    "type(LDA.components_)\n",
    "#it is an array ,containing, the\n",
    "\n",
    "LDA.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "clean-permission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2475, 18302, 35285, ..., 22673, 42561, 42993], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_topic = LDA.components_[0]\n",
    "\n",
    "single_topic.argsort()\n",
    "#arg sort, returns the index positions that would sort this array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "intimate-scott",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([10,200,1])\n",
    "arr\n",
    "\n",
    "arr.argsort()\n",
    "#it would return the index positions from the lowest value to the highest value\n",
    "\n",
    "#argsort, is returning the locations, of the larger values, \n",
    "# we can use this index positions, and get correlated with the feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "classical-adaptation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33390, 36310, 21228, 10425, 31464,  8149, 36283, 22673, 42561,\n",
       "       42993], dtype=int64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ARGSORT ----> INDEX POSITIONS FROM LEAST --> GREATES\n",
    "#TOP 10 VALUES (10 GREATEST VALUES)\n",
    "#LAST 10 VALUES OF ARGSORT()\n",
    "\n",
    "single_topic.argsort()[-10:] #grab the last 10 values of the .argsort()\n",
    "#top 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "saved-berry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new\n",
      "percent\n",
      "government\n",
      "company\n",
      "million\n",
      "care\n",
      "people\n",
      "health\n",
      "said\n",
      "says\n"
     ]
    }
   ],
   "source": [
    "top_ten_words = single_topic.argsort()[-10:]\n",
    "\n",
    "for index in top_ten_words:\n",
    "    print(cv.get_feature_names()[index])\n",
    "    \n",
    "\n",
    "    #LDA is showing us some underlined labelled topics\n",
    "    #these words have high probability, in particular, single_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "plastic-literacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Top 15 words for topic #0\n",
      "['companies', 'money', 'year', 'federal', '000', 'new', 'percent', 'government', 'company', 'million', 'care', 'people', 'health', 'said', 'says']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Top 15 words for topic #1\n",
      "['military', 'house', 'security', 'russia', 'government', 'npr', 'reports', 'says', 'news', 'people', 'told', 'police', 'president', 'trump', 'said']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Top 15 words for topic #2\n",
      "['way', 'world', 'family', 'home', 'day', 'time', 'water', 'city', 'new', 'years', 'food', 'just', 'people', 'like', 'says']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Top 15 words for topic #3\n",
      "['time', 'new', 'don', 'years', 'medical', 'disease', 'patients', 'just', 'children', 'study', 'like', 'women', 'health', 'people', 'says']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Top 15 words for topic #4\n",
      "['voters', 'vote', 'election', 'party', 'new', 'obama', 'court', 'republican', 'campaign', 'people', 'state', 'president', 'clinton', 'said', 'trump']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Top 15 words for topic #5\n",
      "['years', 'going', 've', 'life', 'don', 'new', 'way', 'music', 'really', 'time', 'know', 'think', 'people', 'just', 'like']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Top 15 words for topic #6\n",
      "['student', 'years', 'data', 'science', 'university', 'people', 'time', 'schools', 'just', 'education', 'new', 'like', 'students', 'school', 'says']\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grab the highest probability words per topic\n",
    "\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f\"The Top 15 words for topic #{i}\")\n",
    "    print([cv.get_feature_names()[index] for index in topic.argsort()[-15:]])\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "prepared-belarus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11992, 54777)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "checked-familiar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.61040465e-02 6.83341493e-01 2.25376318e-04 ... 2.99652737e-01\n",
      "  2.25479379e-04 2.25497980e-04]\n",
      " [3.63424997e-02 8.86130697e-01 4.40751747e-04 ... 7.57636804e-02\n",
      "  4.40866779e-04 4.40835574e-04]\n",
      " [3.28569485e-04 6.96344889e-01 3.28302105e-04 ... 3.02012902e-01\n",
      "  3.28724083e-04 3.28352652e-04]\n",
      " ...\n",
      " [1.44467964e-02 1.60696622e-01 1.73678310e-01 ... 2.24636569e-02\n",
      "  3.98728349e-04 3.98359730e-04]\n",
      " [4.33560738e-04 3.53196803e-02 4.33022554e-04 ... 9.62512640e-01\n",
      "  4.33971991e-04 4.33490254e-04]\n",
      " [3.98777533e-01 2.54376049e-04 3.59290659e-01 ... 2.40914375e-01\n",
      "  2.54445555e-04 2.54253739e-04]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11992, 7)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we need to attatch the topic number as a  new column to the original article\n",
    "\n",
    "topic_results =LDA.transform(dtm)\n",
    "print(topic_results)\n",
    "topic_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "positive-design",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results.shape\n",
    "\n",
    "topic_results[0]\n",
    "#these are probabilites, of a documents, belonging to a topic\n",
    "#probabilities \n",
    "\n",
    "topic_results[0].round(2)\n",
    "#we can also round off\n",
    "\n",
    "#here we are interested only in the index positions of the highest probabilites\n",
    "topic_results[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "joint-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "npr['Topic']=topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "surrounded-titanium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>The number of law enforcement officers shot an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>Trump is busy these days with victory tours,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>It’s always interesting for the Goats and Soda...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>The election of Donald Trump was a surprise to...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>Voters in the English city of Sunderland did s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11992 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Article  Topic\n",
       "0      In the Washington of 2016, even when the polic...      1\n",
       "1        Donald Trump has used Twitter  —   his prefe...      1\n",
       "2        Donald Trump is unabashedly praising Russian...      1\n",
       "3      Updated at 2:50 p. m. ET, Russian President Vl...      1\n",
       "4      From photography, illustration and video, to d...      2\n",
       "...                                                  ...    ...\n",
       "11987  The number of law enforcement officers shot an...      1\n",
       "11988    Trump is busy these days with victory tours,...      4\n",
       "11989  It’s always interesting for the Goats and Soda...      3\n",
       "11990  The election of Donald Trump was a surprise to...      4\n",
       "11991  Voters in the English city of Sunderland did s...      0\n",
       "\n",
       "[11992 rows x 2 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
